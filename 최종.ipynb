{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from eunjeon import Mecab\n",
    "tagger = Mecab()\n",
    "\n",
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list=open('analysis_token','r',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "except_words='흠,예,그게,네,아,어,뭐,음,자,이,저,그,때,우리,여러분,번,요,오,앞,뒤,것,여기,저기,이것,저것,이게,저게,이걸,저걸,이번,저번,이런,저런'\n",
    "excpet_words=except_words.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "from korean_romanizer import *\n",
    "import jellyfish\n",
    "\n",
    "\n",
    "def find_error_word(): #오류가 있는지 확인\n",
    "    error_word=[] #오류단어를 저장\n",
    "    for i in jamak_nouns:\n",
    "        if i not in text_list:\n",
    "            error_word.append(i)\n",
    "    return error_word\n",
    "\n",
    "def nearby_error_word(): #오류 단어 앞뒤의 단어 or 앞의 두 단어(오류단어가 가장 마지막에 위치한 경우) 뽑기\n",
    "    check_nouns=[]#오류단어 앞뒤의 단어 저장\n",
    "    for i in range(len(error_word)):\n",
    "        for j in range(len(jamak_nouns)):\n",
    "            if error_word[i] == jamak_nouns[j]:\n",
    "                check_nouns_list=[]\n",
    "                if j == len(jamak_nouns)-1:\n",
    "                    check_nouns_list.append(jamak_nouns[j-1])\n",
    "                    check_nouns_list.append(jamak_nouns[j-2])\n",
    "                    check_nouns_list.append(jamak_nouns[j-3])\n",
    "                else:\n",
    "                    check_nouns_list.append(jamak_nouns[j-1])\n",
    "                    check_nouns_list.append(jamak_nouns[j+1])\n",
    "                    check_nouns_list.append(jamak_nouns[j-2])\n",
    "                check_nouns.append(check_nouns_list)    \n",
    "    return check_nouns\n",
    "\n",
    "\n",
    "def check_word_list(): #오류 단어 근처의 단어에 대해 연관성 높은 단어의 리스트를 저장\n",
    "    word_list=[]\n",
    "    global model_result\n",
    "    if check_nouns==[]:\n",
    "        return []\n",
    "\n",
    "    else:\n",
    "        for i in range(len(check_nouns)):\n",
    "            list_result=[]\n",
    "            for j in check_nouns[i]:\n",
    "                try:\n",
    "                    model_result=model.wv.most_similar(j)\n",
    "                except:\n",
    "                    pass\n",
    "                for k in model_result:\n",
    "                    if k[0] not in except_words:\n",
    "                        list_result.append(k[0])\n",
    "            word_list.append(list_result)\n",
    "   \n",
    "    return word_list\n",
    "\n",
    "\n",
    "def romanizing(): #word_list의 한글 발음을 로마자로 변환\n",
    "    pronounce=[] # word_list의 발음을 저장.\n",
    "    if word_list == []:\n",
    "        return []\n",
    "    else:\n",
    "        for i in range(len(word_list)):\n",
    "            pronounce_list=[]\n",
    "            for j in range(len(word_list[i])):\n",
    "                a=Romanizer(word_list[i][j])\n",
    "                pronounce_list.append(a.romanize())\n",
    "            pronounce.append(pronounce_list)\n",
    "    return pronounce\n",
    "\n",
    "\n",
    "\n",
    "def similarity(): #유사도 측정\n",
    "    probability=[]\n",
    "    if error_word == []:\n",
    "        return []\n",
    "    else:\n",
    "        for e in range(len(error_word)):\n",
    "            a=Romanizer(error_word[e]).romanize()\n",
    "            prob=[]\n",
    "            prob1=[]\n",
    "            prob2=[]\n",
    "            prob3=[]\n",
    "            for j in range(len(pronounce[e])):\n",
    "                prob1.append(jellyfish.jaro_winkler_similarity(a, pronounce[e][j]))\n",
    "                prob2.append(jellyfish.jaro_similarity(a, pronounce[e][j]))\n",
    "                prob3.append(1-(jellyfish.levenshtein_distance(a,pronounce[e][j]))/10)\n",
    "                prob.append(prob3[j]+(prob1[j]+prob2[j])/2)\n",
    "            probability.append(prob)\n",
    "    return probability\n",
    "\n",
    "\n",
    "\n",
    "def word_change(): #오류단어를 교체\n",
    "    global correct_word\n",
    "    correct_word=[]\n",
    "    if error_word==[]:\n",
    "        return jamak\n",
    "    else:\n",
    "        change_word=[]\n",
    "        for i in range(len(probability)):\n",
    "            err_word_index=probability[i].index(max(probability[i]))\n",
    "            correct_word.append(word_list[i][err_word_index])\n",
    "            \n",
    "        for a in range(len(jamak)):\n",
    "            for b in range(len(error_word)):\n",
    "                if jamak[a] == error_word[b]:\n",
    "                    jamak[a]=correct_word[b]\n",
    "    return jamak\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open(r'C:\\Users\\IBK\\fluid_lecture.txt',encoding=\"utf8\") # 자막이 들어올 위치. 자막을 한 줄씩 받을 예정\n",
    "\n",
    "\n",
    "while True:\n",
    "    line=f.readline()\n",
    "    jamak_nn=tagger.nouns(line) #자막에 나오는 의미있는 명사를 찾기\n",
    "    \n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "    \n",
    "    jamak_nouns=[]\n",
    "    for w in jamak_nn:\n",
    "        if w not in except_words:\n",
    "            jamak_nouns.append(w)\n",
    "    \n",
    "    if tagger.morphs(line)!=[]: #자막문장을 품사별로 끊기\n",
    "        jamak=tagger.morphs(line)\n",
    "\n",
    "    #print('자막 = ',jamak)\n",
    "    \n",
    "    #print('자막에 나오는 명사 = ',jamak_nouns)\n",
    "\n",
    "    error_word=find_error_word()\n",
    "    #print('오류 단어 = ',error_word)\n",
    "    \n",
    "    check_nouns=nearby_error_word()\n",
    "    #print('오류 단어 근처의 단어 = ',check_nouns)\n",
    "    \n",
    "    word_list=check_word_list()\n",
    "    #print('오류 단어에 위치할 확률이 높은 단어 = ',word_list)\n",
    "    \n",
    "    pronounce=romanizing()\n",
    "    #print('오류 단어에 위치할 확률이 높은 단어의 발음 = ',pronounce)\n",
    "   \n",
    "    probability=similarity()\n",
    "    #print('오류단어와의 발음의 유사성 계산 = ',probability)\n",
    "    \n",
    "    change_word=word_change()\n",
    "    #print('변환된 자막 = ',change_word)\n",
    "    \n",
    "    \n",
    "    # 자막으로 전환\n",
    "    line=list(line)\n",
    "    space_list=[]\n",
    "    for index, value in enumerate(line):\n",
    "        if value==' ':\n",
    "            space_list.append(index)\n",
    "    #print('space_list = ',space_list)\n",
    "    #print('correct word = ',correct_word)\n",
    "    #print('error word =', error_word)\n",
    "    change_word=list(''.join(change_word))\n",
    "    for i in space_list:\n",
    "        change_word.insert(i,' ')\n",
    "    final_jamak=''.join(change_word)\n",
    "    #print('최종 자막 = ',final_jamak,'\\n')\n",
    "    \n",
    "        \n",
    "    #--------------------------------------------------------------음, 흠, 어 이런거 없애는게 나을지 두는게 나을지\n",
    "    # 단어의 글자수가 다른 경우 띄어쓰기 어떻게 조건을 바꾸어야하지?\n",
    "    \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
